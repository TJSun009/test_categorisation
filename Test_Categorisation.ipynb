{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TJSun009/test_categorisation/blob/main/Test_Categorisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDK45Gxu6gBE"
      },
      "source": [
        "# Plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuTry73ATwWk"
      },
      "outputs": [],
      "source": [
        "# Plan of Action\n",
        "\n",
        "# Source-Test Mapping\n",
        "# Get Graph Representation of Programs\n",
        "# Create a Graph Neural Network Classfier to map src and test graph\n",
        "# (Optional) Enhance graph tokens using GraphCodeBERT, CodeBERT or TREEBERT embeddings\n",
        "\n",
        "# Test Generation\n",
        "# Create a GraphTransformer using Graph Representations and Encoder-Decoder Architecture\n",
        "# Prior Embeddings may be useful\n",
        "# See GraphBERT - https://arxiv.org/abs/2001.05140\n",
        "# Encoder - convert Graph nodes to a node embedding Representation based on surrounding nodes and edges\n",
        "\n",
        "# Use Masked Node Modelling to Mask a Node in the AST and Generate it based on it's connected nodes and edges"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Cloud Storage Setup"
      ],
      "metadata": {
        "id": "X2de2lPwdQXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth login --no-launch-browser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eorg51KqqyQq",
        "outputId": "3e98979c-a62a-4f8c-d8c8-69eb515fdbe3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=7XrsEvQwmbyIGEkKe9DvarWDdiTgdF&prompt=consent&access_type=offline&code_challenge=GnhVDoNciVs6r7fDLqtzE_HAA8PxEsiF0-RJLpbucYk&code_challenge_method=S256\n",
            "\n",
            "Enter authorization code: \n",
            "\n",
            "Command killed by keyboard interrupt\n",
            "\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = \"southern-camera-367511\"\n",
        "bucket_name = \"dissertation-data-bucket-1\"\n",
        "!gcloud config set project {project_id}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25l7dUyUdYTv",
        "outputId": "0b0b89d3-f2ce-4e5b-cbd8-fa1c5f93ab50"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GCS Helpers\n",
        "\n",
        "# copy file to GCS\n",
        "def copy_to_gcs(file_path, options=\"\"):\n",
        "  file_path = file_path.replace(\"/content\", \"\")\n",
        "  command = ! gsutil -m cp{options} {file_path} gs://{bucket_name}/{file_path}\n",
        "\n",
        "# copy file to GCS\n",
        "def copy_from_gcs(src_file_path, dest_file_path=\"\", options=\"\"):\n",
        "  gcs_file_path = src_file_path.replace(\"/content/\", \"\")\n",
        "\n",
        "  dest_file_path = dest_file_path if dest_file_path != \"\" else src_file_path\n",
        "\n",
        "  if not os.path.exists(dest_file_path):\n",
        "    os.makedirs(os.path.dirname(dest_file_path), exist_ok=True)\n",
        "\n",
        "  command = ! gsutil -m cp{options} gs://{bucket_name}/{gcs_file_path} {dest_file_path}\n",
        "  print(\"copied succesfully\")\n",
        "\n",
        "def list_gcs_files(file_path):\n",
        "  file_path = file_path.replace(\"/content/\", \"\")\n",
        "  files = ! gsutil ls gs://{bucket_name}/{file_path}\n",
        "  return files\n",
        "\n",
        "def gcs_file_path_to_colab(gcs_file_path):\n",
        "  return gcs_file_path.replace(f\"gs://{bucket_name}/\", \"/content/\")\n",
        "\n",
        "# check for file in GCS\n",
        "def is_in_gcs(file_path):\n",
        "  file_path = file_path.replace(\"/content/\", \"\")\n",
        "  output = ! gsutil -q stat gs://{bucket_name}/{file_path}; echo $?\n",
        "  return output[0] == '0'"
      ],
      "metadata": {
        "id": "K-7eqv7Pf-XF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjHpv5AIgsJ6"
      },
      "source": [
        "# Source-Test Mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgjOkMrriB-Q"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eiDQAGIjk1ee"
      },
      "outputs": [],
      "source": [
        "! pip install -Uqqq scipy networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NUjrG3-fDDcX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "# import pandas as pd\n",
        "import networkx as nx\n",
        "from glob import iglob\n",
        "import importlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGiAvVTs535v"
      },
      "source": [
        "### python-graphs dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5r31L5nnSeL-"
      },
      "outputs": [],
      "source": [
        "# New Graph Generator Approach\n",
        "# https://arxiv.org/pdf/2208.07461v1.pdf\n",
        "\n",
        "# install python-graphs on startup\n",
        "! echo {SUDO} | sudo -S apt-get -qq -y install graphviz graphviz-dev\n",
        "# ! pip install -Uqqq python-graphs gast==0.3.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/google-research/python-graphs.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e92Y-Tcb25hE",
        "outputId": "61c31d2a-a93d-400c-c54c-ddef29bb1d07"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'python-graphs'...\n",
            "remote: Enumerating objects: 198, done.\u001b[K\n",
            "remote: Counting objects: 100% (198/198), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 198 (delta 109), reused 144 (delta 63), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (198/198), 82.55 KiB | 10.32 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd ./python-graphs && python setup.py develop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSI7Q7wC3C3H",
        "outputId": "70199348-a58e-46e0-f381-b2b1e68ebb0d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running develop\n",
            "running egg_info\n",
            "creating python_graphs.egg-info\n",
            "writing python_graphs.egg-info/PKG-INFO\n",
            "writing dependency_links to python_graphs.egg-info/dependency_links.txt\n",
            "writing requirements to python_graphs.egg-info/requires.txt\n",
            "writing top-level names to python_graphs.egg-info/top_level.txt\n",
            "writing manifest file 'python_graphs.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'python_graphs.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.8/dist-packages/python-graphs.egg-link (link to .)\n",
            "python-graphs 1.3.0 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /content/python-graphs\n",
            "Processing dependencies for python-graphs==1.3.0\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pygraphviz==1.10\n",
            "Best match: pygraphviz 1.10\n",
            "Adding pygraphviz 1.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for networkx==3.0\n",
            "Best match: networkx 3.0\n",
            "Adding networkx 3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for gast==0.3.2\n",
            "Best match: gast 0.3.2\n",
            "Adding gast 0.3.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for astunparse==1.6.3\n",
            "Best match: astunparse 1.6.3\n",
            "Adding astunparse 1.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for absl-py==1.3.0\n",
            "Best match: absl-py 1.3.0\n",
            "Adding absl-py 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for wheel==0.38.4\n",
            "Best match: wheel 0.38.4\n",
            "Adding wheel 0.38.4 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Finished processing dependencies for python-graphs==1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h3hDQAKiSK2"
      },
      "source": [
        "#### Understanding python-graphs Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cr7lEAu3FlxE"
      },
      "outputs": [],
      "source": [
        "# import gast as ast\n",
        "# from python_graphs import program_graph\n",
        "\n",
        "# # example file\n",
        "# file_path = DIR_PREFIX + \"Year 3/Dissertation/Projects/Datasets/data/minified/src/unittest_utils.py\"\n",
        "\n",
        "# with open(file_path, \"r\") as f:\n",
        "#   # graph = program_graph.get_program_graph(f.read())\n",
        "  \n",
        "#   # read ast head\n",
        "#   graph = program_graph.get_program_graph(ast.parse(f.read()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-kauehBVaem2"
      },
      "outputs": [],
      "source": [
        "# # nodes are stored in a dictionary representing a key-value pair of the node id and node itself\n",
        "# example_node_dict = graph.nodes\n",
        "\n",
        "# # nodes are represented as strings by joining the node id and node ast_type if it has one \n",
        "# example_node_dict_item = list(example_node_dict.items())[0]\n",
        "\n",
        "# # item 0 is the node id and item 1 the node representation\n",
        "# example_node_dict_item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kgwVVv1JfKd2"
      },
      "outputs": [],
      "source": [
        "# # as above the node is the value\n",
        "# example_node = example_node_dict_item[1]\n",
        "\n",
        "# # we can view the nodes properties as well\n",
        "# # the ast_value is of particular interest as well for retrieving tokens\n",
        "# # not all nodes will have a value though\n",
        "# print(example_node.__dict__)\n",
        "# print(example_node.__dict__[\"ast_node\"].__dict__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i_9j7z6PFNY8"
      },
      "outputs": [],
      "source": [
        "# # show what ast_values look like\n",
        "# nodes = list(graph.all_nodes())\n",
        "\n",
        "# node_values = []\n",
        "# for node in nodes:\n",
        "#   if node.ast_value:\n",
        "#     node_values.append(node.ast_value)\n",
        "# # some ast_values are long strings so will need subtokens which can be combined\n",
        "# # may require CodeBERT embeddings\n",
        "# node_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NFxwIA9jCZc_"
      },
      "outputs": [],
      "source": [
        "# # check edge\n",
        "# example_edge = graph.edges[0]\n",
        "# example_edge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1fREN-3ktCY"
      },
      "source": [
        "### CodeBERT dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_w0I1cLCVrUb"
      },
      "outputs": [],
      "source": [
        "# imports for tokenising code values\n",
        "! pip install -Uqqq transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3ThqF6zVgR_"
      },
      "source": [
        "#### Investigating CodeBERT Tokeniser for code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoTokenizer, AutoModel\n",
        "# import torch\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "# model = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
      ],
      "metadata": {
        "id": "MDTIheOElCdZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BhXA4pwkc-B9"
      },
      "outputs": [],
      "source": [
        "# # join node values into single string\n",
        "# code = (' ').join([str(val) for val in node_values])\n",
        "# # code\n",
        "# code_tokens = tokenizer.tokenize(code)\n",
        "# # code_tokens\n",
        "# tokens = [tokenizer.cls_token] + code_tokens + [tokenizer.sep_token]\n",
        "# # tokens\n",
        "# tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "# # this is the final output from the model\n",
        "# # it consists of 1 vector for each token across 768 distinct features \n",
        "# context_embeddings = model(torch.tensor(tokens_ids)[None,:])[0]\n",
        "# # context_embeddings.shape\n",
        "# len(code_tokens), context_embeddings.shape\n",
        "\n",
        "# # in the graph embedding the node values could be represented as each value padded\n",
        "# # by N others on either side, N would be calibrated for best results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJq3_r9jFem7"
      },
      "source": [
        "## Prepare Dataset Helpers\n",
        "\n",
        "produces graph_list (list of python_graphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pJy8aIye_hMm"
      },
      "outputs": [],
      "source": [
        "CODE_MINI_DIR =  \"/content/data/minified\"\n",
        "CODE_LARGE_DIR = \"/content/data/large\"\n",
        "CODE_DIR = CODE_MINI_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Yw3GuC2QCiIr"
      },
      "outputs": [],
      "source": [
        "# adapted from typilus for monitoring\n",
        "class Monitoring:\n",
        "    def __init__(self):\n",
        "        self.count = 0  # type: int\n",
        "        self.errors = []\n",
        "        self.file = \"\"  # type: str\n",
        "        self.empty_files = []\n",
        "\n",
        "    def increment_count(self) -> None:\n",
        "        self.count += 1\n",
        "\n",
        "    def found_error(self, err, trace) -> None:\n",
        "        self.errors.append([self.file, err, trace])\n",
        "\n",
        "    def enter_file(self, filename: str) -> None:\n",
        "        self.file = filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "M68kdXVzCq1D"
      },
      "outputs": [],
      "source": [
        "# adapted from typilus for generating graphs with python_graphs\n",
        "\n",
        "from typing import Tuple, List, Optional, Set, Iterator\n",
        "from python_graphs import program_graph\n",
        "\n",
        "# TODO progress bar\n",
        "# from tqdm.notebook import tqdm_notebook\n",
        "\n",
        "\n",
        "# needed to use gast opposed to standard ast\n",
        "import gast, ast\n",
        "def explore_files(root_dir: str, monitoring: Monitoring) -> Iterator[Tuple]:\n",
        "    \"\"\"\n",
        "    Walks through the root_dir and process each file.\n",
        "    \"\"\"\n",
        "    for file_path in iglob(os.path.join(root_dir, '**', '*.py'), recursive=True):\n",
        "        file_name = file_path.split('/').pop()\n",
        "        if not os.path.isfile(file_path):\n",
        "            continue\n",
        "        # print(file_path)\n",
        "        with open(file_path, encoding=\"utf-8\", errors='ignore') as f:\n",
        "            monitoring.increment_count()\n",
        "            monitoring.enter_file(file_path)\n",
        "            \n",
        "            # difficulty parsing some files so had to be skipped\n",
        "            try:\n",
        "              graph = program_graph.get_program_graph(gast.parse(f.read()))\n",
        "              \n",
        "              # identify graph by file_name\n",
        "              graph.filename = file_path[len(root_dir):]\n",
        "              \n",
        "              yield graph\n",
        "            except:\n",
        "              continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "I5m3vcJhENT7"
      },
      "outputs": [],
      "source": [
        "! pip install -Uqqq dill\n",
        "import dill as pickle\n",
        "\n",
        "# handle saving of graphs\n",
        "def save_graphs(graph_list, dir = CODE_DIR):\n",
        "  graph_dir = os.path.join(dir, \"graphs\", \"\")\n",
        "  \n",
        "  if not os.path.exists(graph_dir):\n",
        "    os.makedirs(graph_dir)\n",
        "  \n",
        "  file = os.path.join(graph_dir, \"graphs.pickle\")\n",
        "\n",
        "  pickle.dump(graph_list, open(file, \"wb\"), protocol = pickle.HIGHEST_PROTOCOL)\n",
        "  copy_to_gcs(file)\n",
        "  return file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_pickle_path = os.path.join(CODE_DIR, \"graphs\", \"graphs.pickle\")\n",
        "\n",
        "def create_graph_list(graph_pickle_path=graph_pickle_path):\n",
        "  if not is_in_gcs(graph_pickle_path):\n",
        "    outputs = explore_files(CODE_DIR, monitoring)\n",
        "    graph_list = [graph for graph in outputs]\n",
        "    monitoring = Monitoring()\n",
        "    save_graphs(graph_list)\n",
        "    del(outputs)\n",
        "    del(monitoring)\n",
        "  elif not os.path.exists(graph_pickle_path):\n",
        "    # copy from gcs before reading pickle\n",
        "    copy_from_gcs(graph_pickle_path)\n",
        "  else:\n",
        "    graph_list = pickle.load(open(graph_pickle_path, \"rb\"))\n",
        "  \n",
        "  return graph_list"
      ],
      "metadata": {
        "id": "Gi--_IuitoCe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7jOhrQzPO-i"
      },
      "source": [
        "## Feed Data to Graph Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILzKE0s9F_gU"
      },
      "source": [
        "### Creating CodeGraph Class\n",
        "\n",
        "This class makes use of networkx a popular graph representation library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1DFjEdSGF-ma"
      },
      "outputs": [],
      "source": [
        "# each edge should be weighted differently based on its type, edge should contain types\n",
        "from python_graphs import program_graph_dataclasses\n",
        "\n",
        "# for ast class list\n",
        "import sys, inspect\n",
        "\n",
        "# imports for tokenising code values\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "model = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ],
      "metadata": {
        "id": "XYDzw1GVdjKe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tCUAunHgfRDc"
      },
      "outputs": [],
      "source": [
        "!pip install -Uqqq torch-scatter torch-sparse torch-geometric -f https://pytorch-geometric.com/whl/torch-1.13.0+cu116.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_tokens = tokenizer.tokenize(\"print\")"
      ],
      "metadata": {
        "id": "eJX3E7n27MDY"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Node Feature Helpers"
      ],
      "metadata": {
        "id": "pYH9kJs2dTSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdb\n",
        "# use enum value to set node type\n",
        "# dict updates only keys contained therein\n",
        "# automatic enum conversion\n",
        "def node_types_to_ints(G):\n",
        "  node_type_dict = nx.get_node_attributes(G, \"node_type\")\n",
        "  int_dict = {k: {\"node_type\": v.value} for k, v in node_type_dict.items()}\n",
        "  nx.set_node_attributes(G, int_dict)\n",
        "\n",
        "# use enum class to convert value back\n",
        "def ints_to_node_types(G):\n",
        "  node_type_dict = nx.get_node_attributes(G, \"node_type\")\n",
        "  node_type_dict = {k: {\"node_type\": program_graph_dataclasses.NodeType(v)} for k, v in node_type_dict.items()}\n",
        "  nx.set_node_attributes(G, node_type_dict)\n",
        "\n",
        "# ast type can be dealt with using string byte encoding\n",
        "def ast_types_to_ints(G, ast_types):\n",
        "  ast_type_dict = nx.get_node_attributes(G, \"ast_type\")\n",
        "  int_dict = {k: {\"ast_type\": ast_types.index(v)} if v in ast_types else {\"ast_type\": -1} for k, v in ast_type_dict.items()}\n",
        "  nx.set_node_attributes(G, int_dict)\n",
        "\n",
        "def ints_to_ast_types(G, ast_types):\n",
        "  ast_type_dict = nx.get_node_attributes(G, \"ast_type\")\n",
        "  int_dict = {k: {\"ast_type\": ast_types[v]} for k, v in ast_type_dict.items()}\n",
        "  nx.set_node_attributes(G, int_dict)\n",
        "\n",
        "# ast_value embeddings done using CodeBERT embeddings\n",
        "# N equates to context padding how many subsequent and following tokens are used in embedding\n",
        "def ast_values_to_context_embeddings(G, vocab, N = 1):\n",
        "  ast_value_dict = nx.get_node_attributes(G, \"ast_value\")\n",
        "\n",
        "  embedding_dict = {}\n",
        "\n",
        "  vocab = list(vocab)\n",
        "\n",
        "  for k, v in ast_value_dict.items():\n",
        "\n",
        "    v = str(v)\n",
        "\n",
        "    idx = vocab.index(v)\n",
        "\n",
        "    start, end = idx - N, idx + N\n",
        "\n",
        "    if start > -1:\n",
        "      if end - 1 > len(vocab):\n",
        "        end = len(vocab) - 1\n",
        "    else:\n",
        "      start = 0\n",
        "      end = 2\n",
        "    \n",
        "    # use prior and subsequent words for context\n",
        "    code = ''.join(vocab[start : end + 1])\n",
        "\n",
        "    # always return a code_token of length 3\n",
        "    code_tokens = tokenizer.tokenize(code)[start : end + 1]\n",
        "\n",
        "    if len(code_tokens) == 0:\n",
        "      context_embeddings = torch.zeros(1, 5, 768)\n",
        "    else:\n",
        "      tokens = [tokenizer.cls_token] + code_tokens + [tokenizer.sep_token]\n",
        "\n",
        "      tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "      # this is the final output from the model\n",
        "      # it consists of 1 vector for each token across 768 distinct features \n",
        "      context_embeddings = model(torch.tensor(tokens_ids)[None,:])[0]\n",
        "\n",
        "    embedding_dict[k] = {\"ast_value\": context_embeddings}\n",
        "\n",
        "  nx.set_node_attributes(G, embedding_dict)\n"
      ],
      "metadata": {
        "id": "c54hNyKAdMah"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Edge Feature Helpers"
      ],
      "metadata": {
        "id": "8Gxa_6fQFFSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edge_types_to_ints(G):\n",
        "  edge_type_dict = nx.get_edge_attributes(G, \"type\")\n",
        "  int_dict = {(node1, node2, dir): {\"type\": v.value} for (node1, node2, dir), v in edge_type_dict.items()}\n",
        "  nx.set_edge_attributes(G, int_dict)"
      ],
      "metadata": {
        "id": "HFoN-UBoFD0w"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementation"
      ],
      "metadata": {
        "id": "-tYAVWXzdoN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils.convert import from_networkx\n",
        "\n",
        "# This code graph class represents a combination of all the graphs generated in the code corpus\n",
        "# This code graph class represents a single graph generated in the code corpus\n",
        "class CodeGraph:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.G = nx.MultiDiGraph()\n",
        "    self.vocab = set()\n",
        "    self.identifier = \"\"\n",
        "    self.is_pair = None\n",
        "    self.types = {\n",
        "        \"edge\" : program_graph_dataclasses.EdgeType._member_names_,\n",
        "        \"ast\" : [cls.__name__ for _, cls in inspect.getmembers(sys.modules[\"ast\"], inspect.isclass)]\n",
        "        }\n",
        "\n",
        "  def read(self, graph):\n",
        "\n",
        "    # set identifier to file_name of graph if graph is a module\n",
        "    if (graph.root.ast_type == \"Module\"):\n",
        "      self.identifier = graph.filename\n",
        "    # TODO implement identifier for functions instead\n",
        "\n",
        "    # add nodes to graph along with their attributes\n",
        "    # dict comprehension deduplicates node id\n",
        "    # we can exclude the ast_node as this info should be encoded in the graphs and edges\n",
        "    # exclude instruction temporarily due to complexity\n",
        "    nodes = graph.all_nodes()\n",
        "    self.G.add_nodes_from([(node.id, {k: v for k, v in node.__dict__.items() if k not in [\"id\", \"ast_node\", \"instruction\"]}) for node in nodes])\n",
        "    \n",
        "    # append edges to the graph along with their attributes\n",
        "    # dict comprehension deduplicates node ids for edge\n",
        "    self.G.add_edges_from([(edge.id1, edge.id2, {k: v for k, v in edge.__dict__.items() if k.find(\"id\") == -1 }) for edge in graph.edges])\n",
        "    \n",
        "    # add ast values to vocab\n",
        "    self.vocab.update([str(token) for token in nx.get_node_attributes(self.G, \"ast_value\").values()])\n",
        "\n",
        "  def node_feature_vector_graph(self, H):\n",
        "    \n",
        "    # some node features have been discarded as they are too complex to be used by pytorch\n",
        "    # or replicate info stored elsewhere in the graph\n",
        "\n",
        "    node_type = list(H.nodes(data=\"node_type\"))[0][1]\n",
        "    if not isinstance(node_type, int):\n",
        "      node_types_to_ints(H)\n",
        "      ast_types_to_ints(H, self.types[\"ast\"])\n",
        "      ast_values_to_context_embeddings(H, self.vocab)\n",
        "    \n",
        "    return H\n",
        "  \n",
        "  def edge_feature_vector_graph(self, H):\n",
        "    \n",
        "    # converts edge type to an integer\n",
        "\n",
        "    edge_type = list(H.edges(data=\"type\"))[0][2]\n",
        "    if not isinstance(edge_type, int):\n",
        "      edge_types_to_ints(H)\n",
        "    \n",
        "    return H\n",
        "\n",
        "    \n",
        "\n",
        "    \"\"\"{'node_type': <NodeType.AST_NODE: 1>, \n",
        "      # ignoring instruction due to it being another complex graph\n",
        "      'instruction': <python_graphs.instruction.Instruction object at 0x7ff853d756d0>, \n",
        "      'ast_type': 'Expr', \n",
        "      'ast_value': '', \n",
        "      'syntax': ''}\"\"\"\n",
        "    \n",
        "    # ast_value encoding\n",
        "  \n",
        "  def draw(self):\n",
        "    if len(self.G.nodes) > 0:\n",
        "      # create normalizer for colours\n",
        "      norm = plt.Normalize()\n",
        "\n",
        "      # use vocab and edge_types to generate colours for plot\n",
        "      # edges are mapped to their position in types\n",
        "      token_colors = [self.vocab.index(val) for val in list(nx.get_node_attributes(self.G, \"ast_value\").values())]\n",
        "      edge_type_colors = [edge_type.value for edge_type in list(nx.get_edge_attributes(self.G, \"type\").values())]\n",
        "      \n",
        "      # normalize the colors between [0, 1]\n",
        "      node_color, edge_color = norm(token_colors), norm(edge_type_colors)\n",
        "\n",
        "      fig, ax = plt.subplots(1, 1, figsize=(10, 10));\n",
        "\n",
        "      nx.draw_networkx(self.G, edge_color = edge_color, node_color = node_color, with_labels=True, ax = ax)\n",
        "  \n",
        "  def pytorch_graph(self):\n",
        "    H = self.node_feature_vector_graph(self.G)\n",
        "\n",
        "    P = self.edge_feature_vector_graph(H)\n",
        "\n",
        "    pyg = from_networkx(P)\n",
        "    \n",
        "    if (self.is_pair):\n",
        "      pyg.y = torch.tensor([int(self.is_pair)])\n",
        "    \n",
        "    return "
      ],
      "metadata": {
        "id": "ZNQNLu0zbvTr"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Code Graph List"
      ],
      "metadata": {
        "id": "xRWkelnRF2lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_code_graph_list(graph_list):\n",
        "  code_graph_list = []\n",
        "\n",
        "  for graph in graph_list:\n",
        "    cg = CodeGraph()\n",
        "    cg.read(graph)\n",
        "    code_graph_list.append(cg)\n",
        "\n",
        "  # cleanup graph list\n",
        "  del(graph_list)"
      ],
      "metadata": {
        "id": "Zd_Q_yq3F63p"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove Transformers model and tokenizer from memory"
      ],
      "metadata": {
        "id": "Nm0Iqtv0rC5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del(model)"
      ],
      "metadata": {
        "id": "_cRBj2DcrLb3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(tokenizer)"
      ],
      "metadata": {
        "id": "6KzBVY6irVT3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pairing Graphs"
      ],
      "metadata": {
        "id": "UKiLLhYWCzki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset will consist of:\n",
        "# graph - a graph containing  candidate src graph and test graph\n",
        "# label - a 0 or 1 corresponding to whether the test and src are a valid pairing\n",
        "\n",
        "# filter out combination results that contain two source files or two test files\n",
        "def is_src_test_pair(pair):\n",
        "  graph1, graph2 = pair\n",
        "\n",
        "  # checks both are not the same type of file\n",
        "  return graph1.identifier.find(\"test\") != graph2.identifier.find(\"test\")\n",
        "\n",
        "# function for combining code_graphs\n",
        "def combine_code_graphs(pair):\n",
        "  code_graph1, code_graph2 = pair\n",
        "  # check if the node vectorisation has already happened\n",
        "  node_type_list = [\n",
        "      list(code_graph1.G.nodes(data=\"node_type\"))[0][1],\n",
        "      list(code_graph2.G.nodes(data=\"node_type\"))[0][1],\n",
        "  ]\n",
        "  \n",
        "  if any([isinstance(node_type, int) for node_type in node_type_list]):\n",
        "    raise Exception(\"Cannot combine code graphs that have already been vectorised\")\n",
        "\n",
        "  # uses number of nodes to verify combination graph worked correctly\n",
        "  graph1, graph2 = code_graph1.G, code_graph2.G\n",
        "  \n",
        "  H = nx.disjoint_union(graph1, graph2)\n",
        "\n",
        "  code_graph1.G = H\n",
        "  code_graph1.vocab.update(list(code_graph2.vocab))\n",
        "\n",
        "  # add a property to the code_graph checking whether or not there are a code, test pair\n",
        "  # False for pair, True for non pair\n",
        "  # dealing with file at present\n",
        "  # mapping functions it will require looking at AST calls etc.\n",
        "  code_graph1.is_pair = code_graph1.identifier.replace(\"_test.py\", \"\") == code_graph2.identifier.replace(\"_test.py\", \"\")\n",
        "\n",
        "  # cleanup vars for concurrency\n",
        "  del(graph1)\n",
        "  del(graph2)\n",
        "  del(code_graph2)\n",
        "  del(node_type_list)\n",
        "  del(H)\n",
        "  return code_graph1"
      ],
      "metadata": {
        "id": "HWeiGfM_CxpW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_paired_code_graphs(graph_list, dir = CODE_DIR):\n",
        "  graph_dir = os.path.join(dir, \"graphs\", \"\")\n",
        "  \n",
        "  if not os.path.exists(graph_dir):\n",
        "    os.makedirs(graph_dir)\n",
        "  \n",
        "  file = os.path.join(graph_dir, \"code_graphs.pickle\")\n",
        "\n",
        "  pickle.dump(graph_list, open(file, \"wb\"), protocol = pickle.HIGHEST_PROTOCOL)\n",
        "  copy_to_gcs(file)\n",
        "  # cleanup\n",
        "  del(graph_dir)\n",
        "  del(file)"
      ],
      "metadata": {
        "id": "XYluaANMhL-n"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install bounded-pool-executor\n",
        "# get all possible combinations of code_graphs\n",
        "from itertools import combinations\n",
        "from bounded_pool_executor import BoundedProcessPoolExecutor\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# code_graph_pickle_path = os.path.join(CODE_DIR, \"graphs\", \"code_graphs.pickle\")\n",
        "\n",
        "def create_combined_code_graphs(code_graph_list):\n",
        "  # only regenerated paired graphs if not already pickled\n",
        "  # if not is_in_gcs(code_graph_pickle_path):\n",
        "    # update combined_code_graph_list to contain the combined code graphs with parallelisation\n",
        "    # inline to reduce stored vars\n",
        "  pairs = list(filter(is_src_test_pair, list(combinations(code_graph_list, 2))))\n",
        "    # del(code_graph_list)\n",
        "    \n",
        "    # with BoundedProcessPoolExecutor(max_workers = 10) as executor:\n",
        "    #   combined_code_graph_list = list(executor.map(combine_code_graphs, pairs, chunksize = 1))\n",
        "\n",
        "  combined_code_graph_list = []\n",
        "\n",
        "    # parallelistation hitting RAM limits, using standard loop with dedicated Cloud Instance\n",
        "  for pair in tqdm(pairs):\n",
        "    combined_code_graph_list.append(combine_code_graphs(pair))\n",
        "\n",
        "    # cleanup code_graph_list\n",
        "  del(pairs)\n",
        "    # save_paired_code_graphs(combined_code_graph_list)\n",
        "  # elif not os.path.exists(code_graph_pickle_path):\n",
        "  #   copy_from_gcs(code_graph_pickle_path)\n",
        "  # combined_code_graph_list = pickle.load(open(code_graph_pickle_path, \"rb\"))\n",
        "  # del(code_graph_list)\n",
        "  return combined_code_graph_list"
      ],
      "metadata": {
        "id": "-Y1JhzTIkFHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37414fa6-3f12-42e6-d757-f485f01715ce"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bounded-pool-executor in /usr/local/lib/python3.8/dist-packages (0.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8fX44jExinI"
      },
      "source": [
        "### PyTorch Conversion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Dataset\n",
        "import glob\n",
        "from torch_geometric.data.makedirs import makedirs\n",
        "from itertools import product\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "51lrAu2lK9Z9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_files = [os.path.basename(gcs_file_path_to_colab(file)) for file in list_gcs_files(os.path.join(CODE_DIR, \"src\", \"\"))]\n",
        "RAW_FILES = []\n",
        "for file in source_files:\n",
        "  RAW_FILES.append(os.path.join(\"src\", file))\n",
        "  RAW_FILES.append(os.path.join(\"test\", file.replace(\".py\", \"_test.py\")))\n",
        "\n",
        "PROCESSED_FILES = [file.replace(\".py\", \".pt\") for file in source_files]"
      ],
      "metadata": {
        "id": "VomYTtdHmY1X"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gast\n",
        "from python_graphs import program_graph\n",
        "from contextlib import suppress\n",
        "\n",
        "def save_data(raw_paths, processed_dir):\n",
        "  src_paths, test_paths = [], []\n",
        "\n",
        "  for path in raw_paths:\n",
        "    test_paths.append(path) if path.find(\"_test.py\") != -1 else src_paths.append(path)\n",
        "\n",
        "  source_test_pairs = list(product(src_paths, test_paths))\n",
        "\n",
        "  idx = 0\n",
        "\n",
        "  source_test_pairs = source_test_pairs\n",
        "\n",
        "  for i, (src_path, test_path) in enumerate(pbar := tqdm(source_test_pairs)):\n",
        "    try:\n",
        "      with open(src_path, encoding=\"utf-8\") as f:\n",
        "          src_graph = program_graph.get_program_graph(gast.parse(f.read()))\n",
        "          src_graph.filename = os.path.basename(src_path)\n",
        "\n",
        "      with open(src_path, encoding=\"utf-8\") as f:\n",
        "        test_graph = program_graph.get_program_graph(gast.parse(f.read()))\n",
        "        test_graph.filename = os.path.basename(src_path)\n",
        "    except (TypeError, SyntaxError):\n",
        "      pbar.set_description(f\"Could not parse either {os.path.basename(src_path)} or {os.path.basename(test_path)}\")\n",
        "      continue\n",
        "    \n",
        "    pbar.set_description(f\"pairing [{os.path.basename(src_path)}, {os.path.basename(test_path)}]\")\n",
        "    \n",
        "    src_code_graph = CodeGraph()\n",
        "    src_code_graph.read(src_graph)\n",
        "\n",
        "    test_code_graph = CodeGraph()\n",
        "    test_code_graph.read(test_graph)\n",
        "\n",
        "    combined_code_graph = combine_code_graphs((src_code_graph, test_code_graph))\n",
        "\n",
        "    data = combined_code_graph.pytorch_graph()\n",
        "\n",
        "    torch.save(data, os.path.join(processed_dir, f\"data_{idx}.pt\"))\n",
        "\n",
        "    pbar.set_description(f\"saved data_{idx}.pt\")\n",
        "    \n",
        "    idx += 1\n",
        "\n",
        "class SourceTestDataset(Dataset):\n",
        "  def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
        "      super().__init__(root, transform, pre_transform, pre_filter)\n",
        "\n",
        "  @property\n",
        "  def raw_file_names(self):\n",
        "    return RAW_FILES\n",
        "\n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    return PROCESSED_FILES\n",
        "\n",
        "  def download(self):\n",
        "    # Download to `self.raw_dir`.\n",
        "    copy_from_gcs(os.path.join(self.root, \"src\", ''), os.path.join(self.root, \"raw\", ''), \" -r\")\n",
        "    copy_from_gcs(os.path.join(self.root, \"test\", ''), os.path.join(self.root, \"raw\", ''), \" -r\")\n",
        "\n",
        "  def process(self):\n",
        "    # Read data into huge `Data` list.\n",
        "    pass\n",
        "\n",
        "  def len(self):\n",
        "    return len(self.processed_file_names)\n",
        "\n",
        "  def get(self, idx):\n",
        "    data = torch.load(os.path.join(self.processed_dir, f\"data_{idx}.pt\"))\n",
        "    return data"
      ],
      "metadata": {
        "id": "iI8AOKIDyHn8"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPlC4qLL0CY-",
        "outputId": "0c645df2-7e36-4b74-9d6f-dccaa4c6dba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 1.13.0+cu116\n"
          ]
        }
      ],
      "source": [
        "print(\"PyTorch has version {}\".format(torch.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_paths = [file_path for file_path in iglob(os.path.join(CODE_DIR, \"raw\", '**', '*.py'), recursive=True)]"
      ],
      "metadata": {
        "id": "JBTCFkX9QFPQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_data(raw_paths, os.path.join(CODE_DIR, \"processed\", \"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7668aae02cb240e8a53c72566df44276",
            "29cf7706188d4b949a83d1827925ecf6",
            "b043f4e5a7a243b08e80c004c93e55ce",
            "98e8c2ee50d84b95bbf9a10f0faaf032",
            "814bad835510471b91a4218788892956",
            "a4f718539cd44e37a8e64b304baeabfa",
            "d9b958257b0b4d91b62094249d066195",
            "fb2686df5902403d9a4aa4ba6ea4995a",
            "43498b035fa1467fbcfec02862705b61",
            "a45abcdd2017486eb8809680e42b7a9c",
            "a5ef1dad3b3848159188c7eeb5db8a39"
          ]
        },
        "id": "hOb36f4SRAzm",
        "outputId": "1f163850-8529-413c-cb40-a13459e8ae6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4761 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7668aae02cb240e8a53c72566df44276"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%debug"
      ],
      "metadata": {
        "id": "bankf8RLFRaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl92SSHT0hMt"
      },
      "outputs": [],
      "source": [
        "dataset = SourceTestDataset(root=CODE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/minified/processed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgM5xrTyUJ4r",
        "outputId": "d361cb2b-e428-442d-eea0-ce59cab98500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pre_filter.pt  pre_transform.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect Dataset"
      ],
      "metadata": {
        "id": "ksFoSu69IP1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('====================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "Rv8nGlfyIWFw",
        "outputId": "ce8166d3-f4b6-4c8f-9731-10cf971bf0d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: SourceTestDataset(10):\n",
            "====================\n",
            "Number of graphs: 10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-f372c5080185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Number of graphs: {len(dataset)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Number of features: {dataset.num_features}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Number of classes: {dataset.num_classes}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36mnum_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m         r\"\"\"Returns the number of features per node in the dataset.\n\u001b[1;32m    123\u001b[0m         Alias for :py:attr:`~num_node_features`.\"\"\"\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_node_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36mnum_node_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnum_node_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;34mr\"\"\"Returns the number of features per node in the dataset.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;31m# Do not fill cache for `InMemoryDataset`:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_data_list'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    237\u001b[0m                 or (isinstance(idx, np.ndarray) and np.isscalar(idx))):\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-2a7e5df411e3>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"data_{idx}.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/minified/processed/data_0.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%debug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0USoFtG5Wr0f",
        "outputId": "b94849c1-b539-4908-9b25-274fca253a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m(251)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    249 \u001b[0;31m\u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    250 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 251 \u001b[0;31m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    252 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    253 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> self.processed_dir\n",
            "*** AttributeError: '_open_file' object has no attribute 'processed_dir'\n",
            "ipdb> u\n",
            "> \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m(270)\u001b[0;36m_open_file_like\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    268 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    269 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 270 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    271 \u001b[0;31m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    272 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> u\n",
            "> \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m(771)\u001b[0;36mload\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    769 \u001b[0;31m        \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    770 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 771 \u001b[0;31m    \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    772 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    773 \u001b[0;31m            \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> u\n",
            "> \u001b[0;32m<ipython-input-59-2a7e5df411e3>\u001b[0m(73)\u001b[0;36mget\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     70 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_file_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     71 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     72 \u001b[0;31m  \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 73 \u001b[0;31m    \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"data_{idx}.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     74 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> self.processed_dir\n",
            "'/content/data/minified/processed'\n",
            "--KeyboardInterrupt--\n",
            "ipdb> q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Parameters"
      ],
      "metadata": {
        "id": "rLnWBuZhKZCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_ratio = 0.8\n",
        "batch_size = 64\n",
        "hidden_channels = 64\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "lJHfytlTKcmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train/Test split"
      ],
      "metadata": {
        "id": "7mu7WUHAIgQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(12345)\n",
        "dataset = dataset.shuffle()\n",
        "\n",
        "split_idx = int(len(dataset)*split_ratio)\n",
        "\n",
        "train_dataset = dataset[:split_idx]\n",
        "test_dataset = dataset[split_idx:]\n",
        "\n",
        "print(f'Number of training graphs: {len(train_dataset)}')\n",
        "print(f'Number of test graphs: {len(test_dataset)}')"
      ],
      "metadata": {
        "id": "kZVcVry9Imgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Dataset Loader"
      ],
      "metadata": {
        "id": "4todTZosLdmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "for step, data in enumerate(train_loader):\n",
        "    print(f'Step {step + 1}:')\n",
        "    print('=======')\n",
        "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
        "    print(data)\n",
        "    print()"
      ],
      "metadata": {
        "id": "fHOfyT5JLgVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### neptune.ai Integration"
      ],
      "metadata": {
        "id": "d0CbMz5aqAgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -Uqqq neptune-client\n",
        "import neptune.new as neptune\n",
        "\n",
        "neptune_api_token = getpass(\"Enter your Neptune API token: \")\n",
        "\n",
        "project = \"tjsun009/test-src-classifier\"\n",
        "\n",
        "run = neptune.init_run(\n",
        "    api_token=neptune_api_token,\n",
        "    project=project,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC8TnzX8qJ0A",
        "outputId": "43be4368-b15d-4d8d-bba3-0ae0ad82f350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pq-VyzUwPpw"
      },
      "source": [
        "## Training a Graph Neural Network (GNN)\n",
        "\n",
        "copied from: https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb\n",
        "\n",
        "Training a GNN for graph classification usually follows a simple recipe:\n",
        "\n",
        "1. Embed each node by performing multiple rounds of message passing\n",
        "2. Aggregate node embeddings into a unified graph embedding (**readout layer**)\n",
        "3. Train a final classifier on the graph embedding\n",
        "\n",
        "There exists multiple **readout layers** in literature, but the most common one is to simply take the average of node embeddings:\n",
        "\n",
        "$$\n",
        "\\mathbf{x}_{\\mathcal{G}} = \\frac{1}{|\\mathcal{V}|} \\sum_{v \\in \\mathcal{V}} \\mathcal{x}^{(L)}_v\n",
        "$$\n",
        "\n",
        "PyTorch Geometric provides this functionality via [`torch_geometric.nn.global_mean_pool`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.glob.global_mean_pool), which takes in the node embeddings of all nodes in the mini-batch and the assignment vector `batch` to compute a graph embedding of size `[batch_size, hidden_channels]` for each graph in the batch.\n",
        "\n",
        "The final architecture for applying GNNs to the task of graph classification then looks as follows and allows for complete end-to-end training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN3sRVuaQ88l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59c998ba-b387-4413-d7d3-2101a27495bd"
      },
      "source": [
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # 1. Obtain node embeddings \n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = GCN(hidden_channels=hidden_channels)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(7, 64)\n",
            "  (conv2): GCNConv(64, 64)\n",
            "  (conv3): GCNConv(64, 64)\n",
            "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2Q37tbHyQ6A"
      },
      "source": [
        "Here, we again make use of the [`GCNConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv) with $\\mathrm{ReLU}(x) = \\max(x, 0)$ activation for obtaining localized node embeddings, before we apply our final classifier on top of a graph readout layer.\n",
        "\n",
        "Let's train our network for a few epochs to see how well it performs on the training as well as test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvhgQoO8Svw4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "4d17af35-85c8-4bcd-8e16-c514fd2ff714"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "         out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
        "         loss = criterion(out, data.y)  # Compute the loss.\n",
        "         loss.backward()  # Derive gradients.\n",
        "         optimizer.step()  # Update parameters based on gradients.\n",
        "         optimizer.zero_grad()  # Clear gradients.\n",
        "\n",
        "def test(loader):\n",
        "     model.eval()\n",
        "\n",
        "     correct = 0\n",
        "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
        "         out = model(data.x, data.edge_index, data.batch)  \n",
        "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
        "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
        "\n",
        "\n",
        "for epoch in range(1, 171):\n",
        "    train()\n",
        "    train_acc = test(train_loader)\n",
        "    test_acc = test(test_loader)\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Train Acc: 0.6467, Test Acc: 0.7368\n",
            "Epoch: 002, Train Acc: 0.6467, Test Acc: 0.7368\n",
            "Epoch: 003, Train Acc: 0.6467, Test Acc: 0.7368\n",
            "Epoch: 004, Train Acc: 0.6467, Test Acc: 0.7368\n",
            "Epoch: 005, Train Acc: 0.6467, Test Acc: 0.7368\n",
            "Epoch: 006, Train Acc: 0.6533, Test Acc: 0.7368\n",
            "Epoch: 007, Train Acc: 0.7467, Test Acc: 0.7632\n",
            "Epoch: 008, Train Acc: 0.7267, Test Acc: 0.7632\n",
            "Epoch: 009, Train Acc: 0.7200, Test Acc: 0.7632\n",
            "Epoch: 010, Train Acc: 0.7133, Test Acc: 0.7895\n",
            "Epoch: 011, Train Acc: 0.7200, Test Acc: 0.7632\n",
            "Epoch: 012, Train Acc: 0.7200, Test Acc: 0.7895\n",
            "Epoch: 013, Train Acc: 0.7200, Test Acc: 0.7895\n",
            "Epoch: 014, Train Acc: 0.7133, Test Acc: 0.8421\n",
            "Epoch: 015, Train Acc: 0.7133, Test Acc: 0.8421\n",
            "Epoch: 016, Train Acc: 0.7533, Test Acc: 0.7368\n",
            "Epoch: 017, Train Acc: 0.7400, Test Acc: 0.7632\n",
            "Epoch: 018, Train Acc: 0.7133, Test Acc: 0.8421\n",
            "Epoch: 019, Train Acc: 0.7400, Test Acc: 0.7895\n",
            "Epoch: 020, Train Acc: 0.7533, Test Acc: 0.7368\n",
            "Epoch: 021, Train Acc: 0.7467, Test Acc: 0.7895\n",
            "Epoch: 022, Train Acc: 0.7467, Test Acc: 0.7895\n",
            "Epoch: 023, Train Acc: 0.7533, Test Acc: 0.7895\n",
            "Epoch: 024, Train Acc: 0.7267, Test Acc: 0.8421\n",
            "Epoch: 025, Train Acc: 0.7533, Test Acc: 0.7632\n",
            "Epoch: 026, Train Acc: 0.7533, Test Acc: 0.7632\n",
            "Epoch: 027, Train Acc: 0.7600, Test Acc: 0.8158\n",
            "Epoch: 028, Train Acc: 0.7533, Test Acc: 0.8421\n",
            "Epoch: 029, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 030, Train Acc: 0.7600, Test Acc: 0.8158\n",
            "Epoch: 031, Train Acc: 0.7600, Test Acc: 0.8158\n",
            "Epoch: 032, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 033, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 034, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 035, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 036, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 037, Train Acc: 0.7400, Test Acc: 0.7632\n",
            "Epoch: 038, Train Acc: 0.7667, Test Acc: 0.8158\n",
            "Epoch: 039, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 040, Train Acc: 0.7533, Test Acc: 0.7368\n",
            "Epoch: 041, Train Acc: 0.7467, Test Acc: 0.7368\n",
            "Epoch: 042, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 043, Train Acc: 0.7667, Test Acc: 0.8158\n",
            "Epoch: 044, Train Acc: 0.7533, Test Acc: 0.7632\n",
            "Epoch: 045, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 046, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 047, Train Acc: 0.7667, Test Acc: 0.8158\n",
            "Epoch: 048, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 049, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 050, Train Acc: 0.7667, Test Acc: 0.8158\n",
            "Epoch: 051, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 052, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 053, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 054, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 055, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 056, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 057, Train Acc: 0.7533, Test Acc: 0.7632\n",
            "Epoch: 058, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 059, Train Acc: 0.7800, Test Acc: 0.7632\n",
            "Epoch: 060, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 061, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 062, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 063, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 064, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 065, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 066, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 067, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 068, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 069, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 070, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 071, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 072, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 073, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 074, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 075, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 076, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 077, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 078, Train Acc: 0.7733, Test Acc: 0.8421\n",
            "Epoch: 079, Train Acc: 0.7667, Test Acc: 0.8158\n",
            "Epoch: 080, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 081, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 082, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 083, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 084, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 085, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 086, Train Acc: 0.7800, Test Acc: 0.8158\n",
            "Epoch: 087, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 088, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 089, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 090, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 091, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 092, Train Acc: 0.7800, Test Acc: 0.8158\n",
            "Epoch: 093, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 094, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 095, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 096, Train Acc: 0.7600, Test Acc: 0.7895\n",
            "Epoch: 097, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 098, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 099, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 100, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 101, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 102, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 103, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 104, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 105, Train Acc: 0.7733, Test Acc: 0.7368\n",
            "Epoch: 106, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 107, Train Acc: 0.7733, Test Acc: 0.7105\n",
            "Epoch: 108, Train Acc: 0.8000, Test Acc: 0.7632\n",
            "Epoch: 109, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 110, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 111, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 112, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 113, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 114, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 115, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 116, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 117, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 118, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 119, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 120, Train Acc: 0.8000, Test Acc: 0.7105\n",
            "Epoch: 121, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 122, Train Acc: 0.7667, Test Acc: 0.7105\n",
            "Epoch: 123, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 124, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 125, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 126, Train Acc: 0.7733, Test Acc: 0.7368\n",
            "Epoch: 127, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 128, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 129, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 130, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 131, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 132, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 133, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 134, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 135, Train Acc: 0.8067, Test Acc: 0.7368\n",
            "Epoch: 136, Train Acc: 0.7800, Test Acc: 0.7632\n",
            "Epoch: 137, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 138, Train Acc: 0.8133, Test Acc: 0.7105\n",
            "Epoch: 139, Train Acc: 0.7867, Test Acc: 0.7632\n",
            "Epoch: 140, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 141, Train Acc: 0.8000, Test Acc: 0.6579\n",
            "Epoch: 142, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 143, Train Acc: 0.7933, Test Acc: 0.7632\n",
            "Epoch: 144, Train Acc: 0.7867, Test Acc: 0.7368\n",
            "Epoch: 145, Train Acc: 0.8267, Test Acc: 0.7368\n",
            "Epoch: 146, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 147, Train Acc: 0.7800, Test Acc: 0.7105\n",
            "Epoch: 148, Train Acc: 0.7933, Test Acc: 0.7895\n",
            "Epoch: 149, Train Acc: 0.8200, Test Acc: 0.7105\n",
            "Epoch: 150, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 151, Train Acc: 0.7800, Test Acc: 0.7632\n",
            "Epoch: 152, Train Acc: 0.7867, Test Acc: 0.7632\n",
            "Epoch: 153, Train Acc: 0.8067, Test Acc: 0.7368\n",
            "Epoch: 154, Train Acc: 0.8067, Test Acc: 0.7368\n",
            "Epoch: 155, Train Acc: 0.7867, Test Acc: 0.7632\n",
            "Epoch: 156, Train Acc: 0.7800, Test Acc: 0.7105\n",
            "Epoch: 157, Train Acc: 0.8000, Test Acc: 0.7368\n",
            "Epoch: 158, Train Acc: 0.7800, Test Acc: 0.7368\n",
            "Epoch: 159, Train Acc: 0.7867, Test Acc: 0.7632\n",
            "Epoch: 160, Train Acc: 0.7867, Test Acc: 0.7632\n",
            "Epoch: 161, Train Acc: 0.7800, Test Acc: 0.7632\n",
            "Epoch: 162, Train Acc: 0.7867, Test Acc: 0.7632\n",
            "Epoch: 163, Train Acc: 0.7867, Test Acc: 0.7632\n",
            "Epoch: 164, Train Acc: 0.7800, Test Acc: 0.8158\n",
            "Epoch: 165, Train Acc: 0.7800, Test Acc: 0.8158\n",
            "Epoch: 166, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 167, Train Acc: 0.7867, Test Acc: 0.7895\n",
            "Epoch: 168, Train Acc: 0.7867, Test Acc: 0.7895\n",
            "Epoch: 169, Train Acc: 0.8000, Test Acc: 0.7632\n",
            "Epoch: 170, Train Acc: 0.8000, Test Acc: 0.7632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mTJL0WfzeBq"
      },
      "source": [
        "As one can see, our model reaches around **76% test accuracy**.\n",
        "Reasons for the fluctations in accuracy can be explained by the rather small dataset (only 38 test graphs), and usually disappear once one applies GNNs to larger datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop Neptune"
      ],
      "metadata": {
        "id": "-8vjanQAls2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stop neptune\n",
        "run.stop()"
      ],
      "metadata": {
        "id": "XQ4LwHDMH0DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# idea for doing tested source MLM\n",
        "# provide the source graph as input and mask a node in the test graph randomly\n",
        "# predict what the node is, including node_type, node_value if applicable "
      ],
      "metadata": {
        "id": "3l-ghrohKAcO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "X2de2lPwdQXn",
        "bgjOkMrriB-Q",
        "NGiAvVTs535v",
        "6h3hDQAKiSK2",
        "D3ThqF6zVgR_",
        "LJq3_r9jFem7",
        "ILzKE0s9F_gU",
        "XYDzw1GVdjKe",
        "pYH9kJs2dTSf",
        "-tYAVWXzdoN4",
        "xRWkelnRF2lE",
        "Nm0Iqtv0rC5u",
        "d0CbMz5aqAgR",
        "c5Ehm0ON8sh9",
        "-8vjanQAls2N"
      ],
      "provenance": [],
      "mount_file_id": "1J3-QrijqHd0jsI8uAtQTDWGNkiXTw3sb",
      "authorship_tag": "ABX9TyMkx1G5UeLeUnxnCbxrTBBL",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7668aae02cb240e8a53c72566df44276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29cf7706188d4b949a83d1827925ecf6",
              "IPY_MODEL_b043f4e5a7a243b08e80c004c93e55ce",
              "IPY_MODEL_98e8c2ee50d84b95bbf9a10f0faaf032"
            ],
            "layout": "IPY_MODEL_814bad835510471b91a4218788892956"
          }
        },
        "29cf7706188d4b949a83d1827925ecf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f718539cd44e37a8e64b304baeabfa",
            "placeholder": "​",
            "style": "IPY_MODEL_d9b958257b0b4d91b62094249d066195",
            "value": "pairing [iris_data.py, netutil_test.py]:   5%"
          }
        },
        "b043f4e5a7a243b08e80c004c93e55ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb2686df5902403d9a4aa4ba6ea4995a",
            "max": 4761,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43498b035fa1467fbcfec02862705b61",
            "value": 217
          }
        },
        "98e8c2ee50d84b95bbf9a10f0faaf032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a45abcdd2017486eb8809680e42b7a9c",
            "placeholder": "​",
            "style": "IPY_MODEL_a5ef1dad3b3848159188c7eeb5db8a39",
            "value": " 217/4761 [11:04&lt;79:30:37, 62.99s/it]"
          }
        },
        "814bad835510471b91a4218788892956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4f718539cd44e37a8e64b304baeabfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9b958257b0b4d91b62094249d066195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb2686df5902403d9a4aa4ba6ea4995a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43498b035fa1467fbcfec02862705b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a45abcdd2017486eb8809680e42b7a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5ef1dad3b3848159188c7eeb5db8a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}